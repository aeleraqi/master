# -*- coding: utf-8 -*-
"""Master_New_Data_Prep.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QcqKS5-3xkG2Wr9QlayKt0qwAQzqFZ3p
"""

# ุชุซุจูุช ุงูููุชุจุงุช ุฅุฐุง ูู ุชูู ูุซุจุชุฉ (ูุจูุฆุฉ ูููุงุจ)
!pip install nltk seaborn imblearn tqdm openpyxl

# โ ุชุฃูุฏ ูู ุชุซุจูุช pandarallel ูู ูุด ูุชุซุจุช
!pip install -q pandarallel

# Commented out IPython magic to ensure Python compatibility.
# ุงุณุชูุฑุงุฏ ุงูููุชุจุงุช ุงูุฃุณุงุณูุฉ
import os
import re
import numpy as np
import pandas as pd

# ุฑุจุท ุฌูุฌู ุฏุฑุงูู ูุน ูููุงุจ
from google.colab import drive
drive.mount('/content/drive')

# ูุนุงูุฌุฉ ุงููุตูุต
import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize

# ููุชุจุงุช ุงูุฑุณู ุงูุจูุงูู ูุงูุชุญููู ุงููุฑุฆู
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import plotly.express as px
import plotly.graph_objects as go


# ุชุญุฏูุฏ ุงูููู ุงููุชุทุฑูุฉ
from scipy import stats

# ุงูุชูุงุฒู ูู ุงูุจูุงูุงุช
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.utils import resample

# ุดุฑูุท ุงูุชูุฏู (ุงุฎุชูุงุฑู)
from tqdm.notebook import tqdm

from pandarallel import pandarallel
pandarallel.initialize(progress_bar=True)

"""**ุฏูุฌ ุงูุจูุงูุงุช**"""

# ุชุญุฏูุฏ ูุณุงุฑ ุงููููุงุช
data_path = '/content/drive/MyDrive/Master_New/Raw_Data'

# ุฃุณูุงุก ุงููููุงุช
file_names = ['SANAD.xlsx', 'AFND.xlsx', 'UltimateArabic.xlsx', 'MYDATA.xlsx']

# ูุฑุงุกุฉ ูุฏูุฌ ุงููููุงุช
dfs = []  # ูุชุฎุฒูู DataFrames

for file in file_names:
    file_path = os.path.join(data_path, file)
    if os.path.exists(file_path):
        print(f"Reading file: {file}")
        df_temp = pd.read_excel(file_path, engine='openpyxl')
        df_temp['file_name'] = file  # ุฅุถุงูุฉ ุนููุฏ ุจุงุณู ุงูููู
        dfs.append(df_temp)
    else:
        print(f"File not found: {file}")

# ุฏูุฌ ุงูุจูุงูุงุช ูู DataFrame ูุงุญุฏุฉ
df_combined = pd.concat(dfs, ignore_index=True)

# ูุญุต ุงูุจูุงูุงุช ุงููุฏูุฌุฉ
print("\nโ Combined Dataset Overview:")
print(f"Total rows: {len(df_combined):,}")
print("Columns:", df_combined.columns.tolist())

# ุนุฑุถ ุฃูู ุฎูุณ ุตููู ูู ุงูุจูุงูุงุช
df_combined.head()

"""**ุญุฐู ุงูุตููู ุงูููุฑุฑ ูุงููุงุฑุบุฉ ูู ุนููุฏ ุงููุต**"""

# ูุจู ุงูุญุฐู
print(f"ุนุฏุฏ ุงูุตููู ูุจู ุงูุชูุธูู: {len(df_combined):,}")

# ุญุฐู ุงูุตููู ุงููุงุฑุบุฉ (ุงูุชู ูุง ุชุญุชูู ุนูู ูุต ูู ุนููุฏ ุงูุฎุจุฑ)
df_cleaned = df_combined.dropna(subset=['text'])

# ุญุฐู ุงูุตููู ุงูุชู ูุฏ ุชุญุชูู ุนูู ูุตูุต ูุงุฑุบุฉ ุจุนุฏ ุฅุฒุงูุฉ ุงููุณุงูุงุช
df_cleaned = df_cleaned[df_cleaned['text'].str.strip().astype(bool)]

print(f"ุนุฏุฏ ุงูุตููู ุจุนุฏ ุญุฐู ุงูุตููู ุงููุงุฑุบุฉ: {len(df_cleaned):,}")

# ุญุฐู ุงูุตููู ุงูููุฑุฑุฉ ุจูุงุกู ุนูู ุนููุฏ ุงูุฎุจุฑ (text)
df_cleaned = df_cleaned.drop_duplicates(subset=['text'], keep='first')

print(f"ุนุฏุฏ ุงูุตููู ุจุนุฏ ุญุฐู ุงูุชูุฑุงุฑุงุช: {len(df_cleaned):,}")

# ุฅุนุงุฏุฉ ุชุนููู ููุฑุณ ุงูุจูุงูุงุช
df_cleaned.reset_index(drop=True, inplace=True)

# ูุนุงููุฉ ุงูุจูุงูุงุช ุจุนุฏ ุงูุชูุธูู
df_cleaned.head()

"""**ุชุณููุฉ ุงูุฎูุงูุง ุงููุงุฑุบุฉ ูู ุนููุฏ ุงููุตุฏุฑ ูุงูุชุตููู**"""

# โ ุชูุธูู ุนููุฏ ุงููุคุณุณุฉ (source): ุชุนููุถ ุงููุงุฑุบ ุจู 'not labeled'
df_cleaned['source'] = df_cleaned['source'].fillna('not labeled')
df_cleaned['source'] = df_cleaned['source'].astype(str).str.strip()
df_cleaned['source'] = df_cleaned['source'].replace('', 'not labeled')

# โ ุฅุญุตุงุฆูุงุช ุนุงูุฉ
total_rows = len(df_cleaned)
total_sources = df_cleaned['source'].nunique()
label_column = next((col for col in df_cleaned.columns if 'label' in col.lower() or 'category' in col.lower()), None)
total_categories = df_cleaned[label_column].nunique(dropna=True)

# โ ุชูุฒูุน ุงููุตุงุฏุฑ ูุนุฏุฏ ุงูุฃุฎุจุงุฑ ููุณุจุชูุง
source_counts = df_cleaned['source'].value_counts()
source_percentages = (source_counts / source_counts.sum()) * 100

# โ ุฅูุดุงุก ุฌุฏูู ุงูุชุญููู
source_df = pd.DataFrame({
    'Source': source_counts.index,
    'Count': source_counts.values,
    'Percentage': source_percentages.round(2)
})

# โ ุนุฑุถ ุงูุฅุญุตุงุฆูุงุช ูู ุดูู ูุตู
print("๐ ุฅุญุตุงุฆูุงุช ุนุงูุฉ:")
print(f"- ุนุฏุฏ ุงูุตููู: {total_rows:,}")
print(f"- ุนุฏุฏ ุงููุคุณุณุงุช ุงูุตุญููุฉ: {total_sources}")
print(f"- ุนุฏุฏ ุงูุชุตูููุงุช ุจุนุฏ ุงูุชูุญูุฏ: {total_categories}")

print("\n๐ ุงููุฒู ุงููุณุจู ููู ูุตุฏุฑ:")
print(source_df)

# โ ุฑุณู ุจูุงูู ุชูุงุนูู ุจููู ุฃุฒุฑู ููุญุฏ
fig = px.bar(
    source_df,
    x='Source',
    y='Percentage',
    text='Percentage',
    title='๐ต Percentage of Articles by Source',
    labels={'Percentage': 'Percentage (%)', 'Source': 'Source'},
    color_discrete_sequence=['#1f77b4']
)

fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')
fig.update_layout(
    xaxis_tickangle=-45,
    yaxis=dict(title='Percentage (%)'),
    xaxis=dict(title='Source'),
    plot_bgcolor='white'
)

fig.show()

"""**ุชูุญูุฏ ุทุฑููุฉ ูุชุงุจุฉ ุฃุณูุงุก ุงูุชุตูููุงุช ูุฏูุฌ ุงูุชุตูููุงุงุช ุงููุชุดุงุจูุฉ**"""

import plotly.express as px

# โ 1. ุชูุธูู ุงูุชุตูููุงุช: ุงุณุชุจุฏุงู NaN ุฃู ุงููุฑุงุบุงุช ุจู 'not labeled'
df_cleaned[label_column] = df_cleaned[label_column].fillna('not labeled')
df_cleaned[label_column] = df_cleaned[label_column].astype(str).str.strip()
df_cleaned[label_column] = df_cleaned[label_column].replace('', 'not labeled')

# โ 2. ุชุญููู ุงููุตูุต ุฅูู lowercase
df_cleaned[label_column] = df_cleaned[label_column].str.lower()

# โ 3. ูุงููุณ ุงูุชูุญูุฏ ุงูููุงุฆู
category_mapping = {
    'finance': 'economy',
    'economy': 'economy',

    'politics': 'politics',
    'politic': 'politics',
    'defense': 'politics',

    'sports': 'sports',
    'sport': 'sports',

    'health': 'health',
    'medical': 'health',
    'science': 'health',
    'environment': 'health',
    'envairoment': 'health',

    'tech': 'technology',
    'technology': 'technology',

    'art': 'culture',
    'culture': 'culture',
    'variety': 'culture',
    'diverse': 'culture',
    'society': 'culture',

    'religion': 'religion'
}

# โ 4. ุชุทุจูู ุงูุชูุญูุฏ
df_cleaned[label_column] = df_cleaned[label_column].replace(category_mapping)

# โ 5. ุญุณุงุจ ุงูุชูุฒูุน ุงูููุงุฆู
unified_category_counts = df_cleaned[label_column].value_counts().reset_index()
unified_category_counts.columns = ['Category', 'Count']

# โ 6. ุนุฑุถ ุงููุนูููุงุช ุงููุตูุฉ
print("๐ โ ููุฎุต ุงูุจูุงูุงุช:")
print(f"- ุฅุฌูุงูู ุนุฏุฏ ุงูุตููู: {len(df_cleaned):,}")
print(f"- ุนุฏุฏ ุงูุชุตูููุงุช ุงููุฑูุฏุฉ ุจุนุฏ ุงูุชูุญูุฏ: {df_cleaned[label_column].nunique(dropna=True)}")
print("\nโ ุงูุชูุฒูุน ุงูุฌุฏูุฏ ููุชุตูููุงุช:")
print(unified_category_counts)

# โ 7. ุฑุณู ุจูุงูู ุชูุงุนูู ุจููู ุฃุฒุฑู ููุญุฏ
fig = px.bar(
    unified_category_counts,
    x='Category',
    y='Count',
    text='Count',
    title='๐ต Distribution of News Articles by Category',
    labels={'Count': 'Number of Articles', 'Category': 'Category'},
    color_discrete_sequence=['#1f77b4']
)

fig.update_traces(texttemplate='%{text:,}', textposition='outside')
fig.update_layout(
    xaxis_tickangle=-45,
    yaxis=dict(title='Number of Articles'),
    xaxis=dict(title='Category'),
    plot_bgcolor='white',
    uniformtext_minsize=8,
    uniformtext_mode='hide'
)

fig.show()

"""**ุชุญููู ุงูุชูุฒูุน ุงูุทุจูุนู ุจุญุณุจ ุนุฏุฏ ุงููููุงุช ูู ุงูุฎุจุฑ **"""

# โ ุงูุชุฃูุฏ ูู ุฃู ุนููุฏ wordcounts ุฑููู ููุธูู
df_cleaned['wordcounts'] = pd.to_numeric(df_cleaned['wordcounts'], errors='coerce')
df_cleaned = df_cleaned.dropna(subset=['wordcounts'])

# โ Box Plot 1: ูุฌููุน ุงูุฃุฎุจุงุฑ
fig1 = px.box(
    df_cleaned,
    y='wordcounts',
    title='๐ฆ ุชูุฒูุน ุนุฏุฏ ุงููููุงุช ูู ุฌููุน ุงูุฃุฎุจุงุฑ',
    labels={'wordcounts': 'ุนุฏุฏ ุงููููุงุช'},
    color_discrete_sequence=['#1f77b4']
)
fig1.update_layout(plot_bgcolor='white')
fig1.show()

# โ Box Plot 2: ุญุณุจ ุงูุชุตูููุงุช
fig2 = px.box(
    df_cleaned,
    x=label_column,
    y='wordcounts',
    title='๐ฆ ุชูุฒูุน ุนุฏุฏ ุงููููุงุช ุญุณุจ ุงูุชุตูููุงุช',
    labels={'wordcounts': 'ุนุฏุฏ ุงููููุงุช', label_column: 'ุงูุชุตููู'},
    color_discrete_sequence=['#1f77b4']
)
fig2.update_layout(
    xaxis_tickangle=-45,
    plot_bgcolor='white'
)
fig2.show()

"""**ุญุฐู ุงูุฃุฎุจุงุฑ ุงููุตูุฑุฉ ูุงูููููุฉ ุฌุฏูุง**"""

# ุญุฐู ุงูุฃุฎุจุงุฑ ุงูุฃูู ูู 50 ูุงูุฃุทูู ูู 1000 ูููุฉ
df_filtered = df_cleaned[(df_cleaned['wordcounts'] >= 50) & (df_cleaned['wordcounts'] <= 1000)]

# ุทุจุงุนุฉ ุงูุฅุญุตุงุฆูุงุช ุจุนุฏ ุงูููุชุฑุฉ
print("๐ฆ ุนุฏุฏ ุงูุฃุฎุจุงุฑ ุจุนุฏ ููุชุฑุฉ ุงูุทูู:")
print(f"- ูุจู ุงูููุชุฑุฉ: {len(df_cleaned):,}")
print(f"- ุจุนุฏ ุงูููุชุฑุฉ: {len(df_filtered):,}")

# โ ุงูุชุฃูุฏ ูู ุฃู ุนููุฏ wordcounts ุฑููู ููุธูู
df_cleaned['wordcounts'] = pd.to_numeric(df_cleaned['wordcounts'], errors='coerce')
df_cleaned = df_cleaned.dropna(subset=['wordcounts'])

# โ ููุชุฑุฉ ุงูุฃุฎุจุงุฑ ุจุทูู ูู 50 ุฅูู 1000 ูููุฉ
df_filtered = df_cleaned[(df_cleaned['wordcounts'] >= 50) & (df_cleaned['wordcounts'] <= 1000)]

# โ Box Plot 1: ูุฌููุน ุงูุฃุฎุจุงุฑ ุจุนุฏ ุงูููุชุฑุฉ
fig1 = px.box(
    df_filtered,
    y='wordcounts',
    title='๐ฆ ุชูุฒูุน ุนุฏุฏ ุงููููุงุช ูู ุฌููุน ุงูุฃุฎุจุงุฑ (50 ุฅูู 1000 ูููุฉ)',
    labels={'wordcounts': 'ุนุฏุฏ ุงููููุงุช'},
    color_discrete_sequence=['#1f77b4']
)
fig1.update_layout(plot_bgcolor='white')
fig1.show()

# โ Box Plot 2: ุญุณุจ ุงูุชุตูููุงุช ุจุนุฏ ุงูููุชุฑุฉ
fig2 = px.box(
    df_filtered,
    x=label_column,
    y='wordcounts',
    title='๐ฆ ุชูุฒูุน ุนุฏุฏ ุงููููุงุช ุญุณุจ ุงูุชุตูููุงุช (50 ุฅูู 1000 ูููุฉ)',
    labels={'wordcounts': 'ุนุฏุฏ ุงููููุงุช', label_column: 'ุงูุชุตููู'},
    color_discrete_sequence=['#1f77b4']
)
fig2.update_layout(
    xaxis_tickangle=-45,
    plot_bgcolor='white'
)
fig2.show()

print("๐ ุชุญููู ุนุฏุฏ ุงููููุงุช:")
print(f"- ุงููุชูุณุท: {df_filtered['wordcounts'].mean():.2f}")
print(f"- ุงููุณูุท (median): {df_filtered['wordcounts'].median():.2f}")
print(f"- 90% ูู ุงูุฃุฎุจุงุฑ ุฃูู ูู: {df_filtered['wordcounts'].quantile(0.9):.0f} ูููุฉ")

"""**ููุงุฑูุฉ ุจูู ุนุฏุฏ ุงูุฃุฎุจุงุฑ ุจุญุณุจ ุงููุตุฏุฑ ูุงูุชุตููู ูุจู ุงูุญุฐู ูุจุนุฏู**"""

# ุชุญุฏูุฏ ุงูุฃุนูุฏุฉ
label_column = next((col for col in df_cleaned.columns if 'label' in col.lower() or 'category' in col.lower()), None)
source_column = 'source'

# โ ููุงุฑูุฉ ุงููุตุงุฏุฑ
source_before = df_cleaned[source_column].value_counts().reset_index()
source_before.columns = ['Source', 'Count']
source_before['Dataset'] = 'ูุจู ุงูููุชุฑุฉ'

source_after = df_filtered[source_column].value_counts().reset_index()
source_after.columns = ['Source', 'Count']
source_after['Dataset'] = 'ุจุนุฏ ุงูููุชุฑุฉ'

source_combined = pd.concat([source_before, source_after])

fig1 = px.bar(
    source_combined,
    x='Source',
    y='Count',
    color='Dataset',
    barmode='group',
    title='๐ ููุงุฑูุฉ ุชูุฒูุน ุงูุฃุฎุจุงุฑ ุญุณุจ ุงููุตุงุฏุฑ (ูุจู ูุจุนุฏ ุงูููุชุฑุฉ)',
    labels={'Count': 'ุนุฏุฏ ุงูุฃุฎุจุงุฑ', 'Source': 'ุงููุตุฏุฑ'},
    color_discrete_sequence=['#1f77b4', '#ff7f0e']
)
fig1.update_layout(xaxis_tickangle=-45, plot_bgcolor='white')
fig1.show()

# โ ููุงุฑูุฉ ุงูุชุตูููุงุช
cat_before = df_cleaned[label_column].value_counts().reset_index()
cat_before.columns = ['Category', 'Count']
cat_before['Dataset'] = 'ูุจู ุงูููุชุฑุฉ'

cat_after = df_filtered[label_column].value_counts().reset_index()
cat_after.columns = ['Category', 'Count']
cat_after['Dataset'] = 'ุจุนุฏ ุงูููุชุฑุฉ'

cat_combined = pd.concat([cat_before, cat_after])

fig2 = px.bar(
    cat_combined,
    x='Category',
    y='Count',
    color='Dataset',
    barmode='group',
    title='๐ ููุงุฑูุฉ ุชูุฒูุน ุงูุฃุฎุจุงุฑ ุญุณุจ ุงูุชุตูููุงุช (ูุจู ูุจุนุฏ ุงูููุชุฑุฉ)',
    labels={'Count': 'ุนุฏุฏ ุงูุฃุฎุจุงุฑ', 'Category': 'ุงูุชุตููู'},
    color_discrete_sequence=['#1f77b4', '#ff7f0e']
)
fig2.update_layout(xaxis_tickangle=-45, plot_bgcolor='white')
fig2.show()

"""**ุงุญุตุงุฆูุงุช ุนู ุงูุจูุงูุงุช ุงูุขู**"""

# โ ุงูุชุฃูุฏ ูู ุงูุฃุนูุฏุฉ
label_column = next((col for col in df_filtered.columns if 'label' in col.lower() or 'category' in col.lower()), None)
source_column = 'source' if 'source' in df_filtered.columns else None

# โ ุฅุญุตุงุฆูุงุช ุฃุณุงุณูุฉ
total_rows = len(df_filtered)
total_categories = df_filtered[label_column].nunique(dropna=True)
total_sources = df_filtered[source_column].nunique(dropna=True)

print("๐ ุฅุญุตุงุฆูุงุช ุนุงูุฉ ุนูู ุงูุจูุงูุงุช ุจุนุฏ ุงูููุชุฑุฉ:")
print(f"- ุนุฏุฏ ุงูุตููู: {total_rows:,}")
print(f"- ุนุฏุฏ ุงูุชุตูููุงุช ุงููุฑูุฏุฉ: {total_categories}")
print(f"- ุนุฏุฏ ุงููุตุงุฏุฑ ุงููุฑูุฏุฉ: {total_sources}")

# โ ุชูุฒูุน ุงููุตุงุฏุฑ
print("\n๐ ุชูุฒูุน ุนุฏุฏ ุงูุฃุฎุจุงุฑ ุญุณุจ ุงููุตุงุฏุฑ:")
source_counts = df_filtered[source_column].value_counts()
print(source_counts)

# โ ุชูุฒูุน ุงูุชุตูููุงุช
print("\n๐ ุชูุฒูุน ุนุฏุฏ ุงูุฃุฎุจุงุฑ ุญุณุจ ุงูุชุตูููุงุช:")
category_counts = df_filtered[label_column].value_counts()
print(category_counts)

"""**ุชูุธูู ุนููุฏ ุงููุต**"""

import re
from pandarallel import pandarallel

# ุชููุฆุฉ pandarallel ูุน ุชูุนูู ุดุฑูุท ุงูุชูุฏู
pandarallel.initialize(progress_bar=True)

def tag_special_tokens(text):
    # ุชุญููู ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ ูุฅูุฌููุฒูุฉ
    text = text.translate(str.maketrans('ููกูขูฃูคูฅูฆูงูจูฉ', '0123456789'))

    # ุงุณุชุจุฏุงู ุงูุชูุงุฑูุฎ ุงูุฑูููุฉ ุจุฃููุงุท ูุฎุชููุฉ
    text = re.sub(
        r'\b(?:\d{1,2}[-/]\d{1,2}[-/]\d{2,4}|\d{4}[-/]\d{1,2}[-/]\d{1,2})\b',
        ' <DATE> ', text
    )
    text = re.sub(r'\b(20[0-5][0-9]|19[7-9][0-9])\b', ' <DATE> ', text)

    # ุงุณุชุจุฏุงู ุฃุณูุงุก ุงูุดููุฑ ุงูุนุฑุจูุฉ
    text = re.sub(r'\b(ููุงูุฑ|ูุจุฑุงูุฑ|ูุงุฑุณ|ุฅุจุฑูู|ูุงูู|ููููู|ููููู|ุฃุบุณุทุณ|ุณุจุชูุจุฑ|ุฃูุชูุจุฑ|ููููุจุฑ|ุฏูุณูุจุฑ)/?\b', ' <DATE> ', text)

    # ุงุณุชุจุฏุงู ุงูุฃุฑูุงู (ุจูุง ูููุง ุงูุญุงูุงุช ูุซู "5 ุขูุงู")
    text = re.sub(r'(?<!\w)\d+\s*(?:ุฃูู|ุขูุงู|ุงูู)?(?!\w)', ' <NUM> ', text)
    text = re.sub(r'(?<!\w)\d+(\.\d+)?(?!\w)', ' <NUM> ', text)

    # ุงุณุชุจุฏุงู ุงูุนููุงุช
    currency_patterns = [
        r'ุฌููู(?:ุงู|ูุง|ุงุช|ุงู|ูู)?',
        r'ุฏููุงุฑ(?:ุงู|ูุง|ุงุช|ุงู|ูู)?',
        r'ุฑูุงู(?:ุงู|ูุง|ุงุช|ุงู|ูู)?',
        r'ุฏุฑูู(?:ุงู|ูุง|ุงุช|ุงู|ูู)?',
        r'โฌ|ยฃ|ยฅ|USD|EGP|SAR|AED'
    ]
    for pattern in currency_patterns:
        text = re.sub(fr'\b{pattern}\b', ' <CURRENCY> ', text, flags=re.IGNORECASE)

    # ุงุณุชุจุฏุงู ุงูููุช
    time_pattern = re.compile(
        r'\b([01]?[0-9]|2[0-3])[:ูซุ]?[0-5][0-9]?\s*(?:ุต|ุตุจุงุญุงู|ู|ูุณุงุก|am|pm|AM|PM)?\b',
        re.IGNORECASE
    )
    text = time_pattern.sub(' <TIME> ', text)

    # ุงุณุชุจุฏุงู ุงูุชุฑุชูุจ
    ordinals = [
        'ุงูุฃูู', 'ุงูุซุงูู', 'ุงูุซุงูุซ', 'ุงูุฑุงุจุน', 'ุงูุฎุงูุณ',
        'ุงูุณุงุฏุณ', 'ุงูุณุงุจุน', 'ุงูุซุงูู', 'ุงูุชุงุณุน', 'ุงูุนุงุดุฑ',
        'ุงูุญุงุฏู ุนุดุฑ', 'ุงูุซุงูู ุนุดุฑ', 'ุงูุฑุงุจุนู', 'ุงูุฑุงุจุนุฉ'
    ]
    for o in ordinals:
        text = re.sub(fr'\b{o}\b', ' <ORDINAL> ', text, flags=re.IGNORECASE)

    # ุงุณุชุจุฏุงู ุงููุญุฏุงุช
    units = ['ูููู', 'ูุฌู', 'ุฌุฑุงู', 'ุทู', 'ูุชุฑ', 'ูุชุฑ', 'ุณู', 'ูููู', 'ูููููุชุฑ', 'ูููุฌุฑุงู']
    for u in units:
        text = re.sub(fr'\b{u}\b', ' <UNIT> ', text)

    return text

def protect_special_tokens_arabic(text):
    """
    ุญูุงูุฉ ุงูุฑููุฒ ุงูุฎุงุตุฉ ุนู ุทุฑูู ุงุณุชุจุฏุงููุง ุจูุตูุต ุนุฑุจูุฉ ูุง ุชุญุชูู ุนูู ุฃุญุฑู ูุงุชูููุฉ ุฃู ุนูุงูุงุช ุชุฑููู.
    """
    mapping = {
        '<NUM>': 'ุฑููุฎุงุต',
        '<DATE>': 'ุชุงุฑูุฎุฎุงุต',
        '<CURRENCY>': 'ุนููุฉุฎุงุต',
        '<TIME>': 'ููุชุฎุงุต',
        '<ORDINAL>': 'ุชุฑุชูุจุฎุงุต',
        '<UNIT>': 'ูุญุฏุฉุฎุงุต'
    }
    for eng, arb in mapping.items():
        text = text.replace(eng, arb)
    return text

def shield_protected_tokens(text):
    """
    ุฅุถุงูุฉ ูุณุงูุงุช ูุจู ูุจุนุฏ ุงูุฑููุฒ ุงููุญููุฉ ูุถูุงู ุนุฒููุง ุนู ุจุงูู ุงููุตุ
    ุญุชู ูู ูุงูุช ูุญุตูุฑุฉ ุจูู ุนูุงูุงุช ุชุฑููู ูุง ุชูุฒุงู.
    """
    protected = ['ุฑููุฎุงุต', 'ุชุงุฑูุฎุฎุงุต', 'ุนููุฉุฎุงุต', 'ููุชุฎุงุต', 'ุชุฑุชูุจุฎุงุต', 'ูุญุฏุฉุฎุงุต']
    for token in protected:
        # ุฅุฐุง ูุงู ุงูุฑูุฒ ููุชุตูุงู ุจูููุฉ ุฃู ุนูุงูุฉุ ูุถูู ูุณุงูุฉ ูุจููุง
        text = re.sub(r'(?<!\s)(' + re.escape(token) + r')', r' \1', text)
        # ููุถูู ูุณุงูุฉ ุจุนุฏูุง ุฅุฐุง ูุงูุช ูุชูุงุตูุฉ ูุน ุญุฑู ุขุฎุฑ
        text = re.sub(r'(' + re.escape(token) + r')(?!\s)', r'\1 ', text)
    return text

def restore_special_tokens_arabic(text):
    """
    ุงุณุชุฑุฌุงุน ุงูุฑููุฒ ุงูุฎุงุตุฉ ุงููุญููุฉ ูู ุงููุต (ุงูููุชูุจุฉ ุจุงูุนุฑุจูุฉ) ุฅูู ุดูููุง ุงูุฃุตูู.
    """
    mapping = {
        'ุฑููุฎุงุต': '<NUM>',
        'ุชุงุฑูุฎุฎุงุต': '<DATE>',
        'ุนููุฉุฎุงุต': '<CURRENCY>',
        'ููุชุฎุงุต': '<TIME>',
        'ุชุฑุชูุจุฎุงุต': '<ORDINAL>',
        'ูุญุฏุฉุฎุงุต': '<UNIT>'
    }
    for arb, eng in mapping.items():
        text = text.replace(arb, eng)
    return text

def basic_text_cleaning(text):
    """
    ุชูุธูู ุงููุต ูู ุงูุฅูููุฌู ูุงููุงุดุชุงุฌุงุช ูุงููููุดูุงุช ูุงูุฑูุงุจุทุ
    ุฅุฒุงูุฉ ุงูุชุดููู ูุงูุฑููุฒ ุงููุฎููุฉ ูุนูุงูุงุช ุงูุชุฑููู (ุนู ุทุฑูู ุงุณุชุจุฏุงููุง ุจูุณุงูุฉ)
    ุจุงูุฅุถุงูุฉ ุฅูู ุชุทุจูุน ุงูุญุฑูู ูุฅุฒุงูุฉ ุงูุฃุญุฑู ุงูุฅูุฌููุฒูุฉ.
    ูุจู ุฐูู ูุถูู ุนุฒู ุงูุฑููุฒ ุงููุญููุฉ ุจุงุณุชุฎุฏุงู ุฏุงูุฉ shield.
    """
    # ุญูุงูุฉ ุนุฒู ุงูุฑููุฒ ุงููุญููุฉ
    text = shield_protected_tokens(text)

    # ุฅุฒุงูุฉ ุงูุฅูููุฌู
    text = re.sub(r'[\U00010000-\U0010ffff]', '', text)
    # ุฅุฒุงูุฉ ุงููุงุดุชุงุฌุงุช ูุงููููุดูุงุช ูุงูุฑูุงุจุท
    text = re.sub(r'#\S+', '', text)
    text = re.sub(r'@\S+', '', text)
    text = re.sub(r'http[s]?://\S+', '', text)
    # ุฅุฒุงูุฉ ุงูุชุดููู ูุงูุฑููุฒ ุงููุฎููุฉ
    text = re.sub(r'[\u064B-\u065F\u0670\u08D3-\u08E1]', '', text)
    text = re.sub(r'[\u200B-\u200F\u202A-\u202E\u2066-\u2069]', '', text)

    # ุฅุฒุงูุฉ ุนูุงูุงุช ุงูุชุฑููู (ุนู ุทุฑูู ุงุณุชุจุฏุงููุง ุจูุณุงูุฉ)
    all_punctuations = (
        '.ุ,:;โฆุ!"#$%&\'()*+,-โ:;<=>ุ?@[\\]^_`{|}~'
        'ยกยฟโโโยซยปโนโบโโโโโโโโโฒโณโตโถโธดโธต'
        'ใ๏ผ๏ผุุ๏ผใใใใใใใใใ๏ฟฅ'
        'เฅฅ'
        'ููซูฌูญูฎูฐูฑกขฃคฅฆงจฉชซฌญฎฏ'
        'โโกโฐโนโบโปโโโโโโโโโโโ'
        'โจโฉโชโซโฌโญโฎโฏโฆโฆโฆโฆโฆโฆโฆโฆ'
        'โฝโพโโ'
        'ใใใใใใใใใใใใใใใใใใใใใใใใใใใใ'
        'ใใใ๏น๏น๏น๏น๏น๏น๏ฝ๏ฝ'
    )
    text = re.sub(f'[{re.escape(all_punctuations)}]', ' ', text)

    # ุชูููู ุงูุญุฑูู ุงูููุฑุฑุฉ
    text = re.sub(r'(.)\1{2,}', r'\1\1', text)

    # ุชุทุจูุน ุงูุญุฑูู
    text = re.sub(r'ู', 'ู', text)
    text = re.sub(r'ุค', 'ู', text)
    text = re.sub(r'ุฉ', 'ู', text)
    text = re.sub(r'[ุฅุฃูฑุขุง]', 'ุง', text)
    text = re.sub(r'ฺฏ', 'ู', text)
    text = re.sub(r'ฺค', 'ู', text)
    text = re.sub(r'ฺ', 'ุฌ', text)
    text = re.sub(r'ูพ', 'ุจ', text)

    # ุฅุฒุงูุฉ ุงูุฃุญุฑู ุงูุฅูุฌููุฒูุฉ (ุงูุชู ูู ูุญูููุง)
    text = re.sub(r'[A-Za-z]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()

    return text

def full_text_cleaning(text):
    """
    ุฏูุฌ ุฎุทูุงุช ุงูุชูุธูู:
      1. ุงุณุชุฎุฑุงุฌ ุงูุฑููุฒ ุงูุฎุงุตุฉ (tag).
      2. ุญูุงูุฉ ุงูุฑููุฒ ุงูุฎุงุตุฉ ุจูุตูุต ุนุฑุจูุฉ ูุงุจูุฉ ููุญูุงูุฉ.
      3. ุชูุธูู ุงููุต ุงูุฃุณุงุณู.
      4. ุงุณุชุฑุฌุงุน ุงูุฑููุฒ ุงูุฎุงุตุฉ ุฅูู ุดูููุง ุงูุฃุตูู.
    """
    text = tag_special_tokens(text)
    text = protect_special_tokens_arabic(text)
    text = basic_text_cleaning(text)
    text = restore_special_tokens_arabic(text)
    return text

# ุชููุฆุฉ pandarallel ูุน ุชูุนูู ุดุฑูุท ุงูุชูุฏู
pandarallel.initialize(progress_bar=True)

# ููุชุฑุถ ุฃู df_filtered ูู DataFrame ุงูููุฌูุฏ ูุฏูู ูุงูุนููุฏ "text" ูุญุชูู ุนูู ุงููุตูุต

# ุฅูุดุงุก ูุณุฎุฉ ูู ุงูู DataFrame ุงูุฃุตูู ูุชุทุจูู ุงูุชูุธูู ุนูููุง
df_filtered_clean = df_filtered.copy()

# ุชุทุจูู ุฏุงูุฉ full_text_cleaning ุนูู ุนููุฏ "text" ุจุงุณุชุฎุฏุงู parallel_apply
df_filtered_clean['cleaned_text'] = df_filtered_clean['text'].parallel_apply(full_text_cleaning)

"""**ููุงุฑูุฉ ุงููุต ูุจู ุงูุชูุธูู ูุจุนุฏู**"""

df_filtered.loc[df_filtered.index[160], 'text']

df_filtered_clean.loc[df_filtered_clean.index[160], 'cleaned_text']

"""**ุงูุชูุงุฒู ุจุทุฑููุฉ Oversampling**"""

from sklearn.utils import resample

# ุชุญุฏูุฏ ุนููุฏ ุงูุชุตููู
label_column = next((col for col in df_filtered_clean.columns if 'label' in col.lower() or 'category' in col.lower()), None)

# ุนุฑุถ ุงูุชูุฒูุน ูุจู ุงูุชูุงุฒู
print("๐ ุชูุฒูุน ุงูุชุตูููุงุช ูุจู ุงูุชูุงุฒู:")
print(df_filtered_clean[label_column].value_counts())

# ุงูุญุฏ ุงูุฃุนูู (ูุณุชูุฏู ูุณุงูุงุฉ ุงูุฌููุน ุจุฃูุซุฑ ูุฆุฉ ุชูุซูููุง)
target_size = df_filtered_clean[label_column].value_counts().max()

# ุนูู Oversampling ููู ุชุตููู
balanced_frames = []
for label, group in df_filtered_clean.groupby(label_column):
    if len(group) < target_size:
        upsampled = resample(group, replace=True, n_samples=target_size, random_state=42)
    else:
        upsampled = group.copy()
    balanced_frames.append(upsampled)

# ุฅูุดุงุก ุงููุณุฎุฉ ุงููุชูุงุฒูุฉ ูุชุฌููุนูุง
df_balanced = pd.concat(balanced_frames).sample(frac=1, random_state=42).reset_index(drop=True)

print("\nโ ุชูุฒูุน ุงูุชุตูููุงุช ุจุนุฏ ุงูุชูุงุฒู:")
after_dist = df_balanced[label_column].value_counts()
print(after_dist)

print(f"โ ุนุฏุฏ ุงูุตููู ุจุนุฏ ุงูุชูุงุฒู: {len(df_balanced):,}")

"""**ุญูุท ูุงูุฉ ุงูุจูุงูุงุช ูู Google Drive**"""

from google.colab import drive
import os
import time

# ุชุฑููุจ Google Drive
drive.mount('/content/drive')

# ุชุนุฑูู ูุณุงุฑ ุงููุฌูุฏ ุงูุฌุฏูุฏ ุฏุงุฎู Master_New
save_path = '/content/drive/MyDrive/Master_New/DataPrep'
os.makedirs(save_path, exist_ok=True)

# ุงูุชุฃูุฏ ูู ุฅูุดุงุก ุงููุฌูุฏ
time.sleep(2)  # ุงูุชุธุงุฑ ูุตูุฑ ูุชุฒุงูู Drive
if os.path.exists(save_path):
    print(f"Directory {save_path} exists or was created.")
else:
    raise Exception(f"Directory {save_path} could not be created.")

# ุญูุธ ุงููููุงุช ูู ุงููุฌูุฏ ุงูุฌุฏูุฏ
df_combined.to_csv(f"{save_path}/00_merged_raw.csv", index=False)
df_cleaned.to_csv(f"{save_path}/01_cleaned_no_duplicates.csv", index=False)
df_filtered.to_csv(f"{save_path}/02_filtered_by_length.csv", index=False)
df_filtered_clean.to_csv(f"{save_path}/03_cleaned_text_final.csv", index=False)
df_balanced.to_csv(f"{save_path}/04_balanced_data.csv", index=False)

print("All files saved successfully.")